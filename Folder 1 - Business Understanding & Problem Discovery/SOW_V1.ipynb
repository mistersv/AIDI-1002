{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1><center>Credit Card Fraud Detection</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image.jpeg\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rational Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Although the increasing digitalization of the payments and money transfer services has indisputable benefits, it has some disadvantages as well. Certainly, one of these is the growth of frauds.  According to the Nilson Report, publication covering the card and mobile payment industry, payment card fraud losses worldwide reached US\\$27.85 billion in 2018 and are expected to rise to $35.67 billion in 2024.</p> \n",
    "\n",
    "<p style='text-align: justify;'> As transaction times becomes faster and fraudster schemes are continuously innovating, it is almost impossible to identify, predict and  counteract fraudulent operations without an robust automation process. Thus, trying to reduce their loss payouts, payment card issuers and merchants have been trying ingenious tools. Machine learning, for instance, is one of the most efficient and, therefore, is progressively being used.  </p>\n",
    "\n",
    "\n",
    "<p style='text-align: justify;'> Hence, in line with market trends, this project aims to build a machine learning model that, based on labeled historical data, detect fraudulent operations. </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>The dataset, gathered from Kaggle.com, comprises of 284,807 credit card operations, being 284,315 non-fraudulent and 492 fraudulents. Therefore, highly unbalaced.</p> \n",
    "    \n",
    "<p style='text-align: justify;'>There are a total of 31 features, all of them numerical. Due to confidentiality reasons, Principal Component Analysis was used to transform data from 28 features. The only features which have not been transformed are: Time, Amount and Class. The first refers to the time elapsed between each transaction and the first one occured in the dataset. The second is the transaction amount. Lastly, the third is a binary variable, which has value 1 for fraudulent transactions and 0 otherwise.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions, Limitations and Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>The first challenge is to handle the unbalanced data. In this case, in order to verify the quality of the model, we can not rely only in its accuracy. In other words, we will need additional metrics, such as precision and recall, to be certain of its quality.</p>\n",
    "\n",
    "<p style='text-align: justify;'>Considering the trade off between false positive and false negative predictions, as we are dealing with frauds, it is better to try to minimize the ratio of false negatives. That is, fraudulent transaction considered as non-fraudulent.</p>  \n",
    "\n",
    "<p style='text-align: justify;'>Another critical question is the wide range of the variable ‘Amount’, which goes from $0 to \\$25,691.16. Since, depending on the model being used, the great difference in scales between variables might bias it towards one feature, we should opt for feature scaling.</p> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>To guarantee the quality of the work, three machine learning models will be fitted and tested: logistic regression, KNN and random forest. Before doing it, however, we will identify and eventually replace missing values. Similar treatment will be used for the outliers </p>.\n",
    "\n",
    "<p style='text-align: justify;'> Regarding the skewness of the variable Class, our target, and the best way to deal with it, we can choose between two methods. One is over-sampling, that is, duplicating data in the minority class or fraudulent transactions. The other is to synthesize data from existing ones.</p>\n",
    "\n",
    "<p style='text-align: justify;'>Finally, in order to avoid overfitting, the k-fold cross-validation technique will be used.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
